%! Author = Vova
%! Date = 13.07.2021

% Preamble
\documentclass[11pt]{article}


% Packages
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{polyglossia}
\usepackage{graphicx}
\usepackage{babel,blindtext}
\usepackage{subfig}
\usepackage{iftex}

% Language and Font settings

% Kurale
% New Standard Old

\setdefaultlanguage{russian}
\setmainfont[Ligatures=TeX]{Kurale}
\newfontfamily\cyrillicfont{Kurale}

\title{Описание программной части робота-художника}
\author{Латыпов Владимир Витальевич}
\date{\today}

% Document
\begin{document}
    \maketitle
    \newpage


    \section{Формулировка задачи}

    Для того, чтобы робот-художник нарисовал что-либо, ему нужно предоставить данные в определённом формате, а именно — не набор пикселей,
    как требуется для показа на мониторе, а набор «мазков»: это связано с конструкцией самого робота.
    Мазки решено было представлять в виде кривых безье второго порядка (то есть квадратичных), к которым добавлены параметры «толщина» и «цвет».

    Но на вход подаются рисунки не в векторном, а в растровом формате.
    Найти такую комбинацию мазков, которая бы лучше всего соответствовала картине/изображению — задача нетривиальная, имеющая множество решений.

    Конечно же, я выбрал решать задачу самостоятельно, а не использовать готовые библиотеки.

    \section{Описание программы в общих чертах}\label{sec:approx_description}
    Таким образом, решено было использовать эвристические алгоритмы оптимизации:
    \href{https://en.wikipedia.org/wiki/Simulated_annealing}{Генетический алгоритм} и \href{https://en.wikipedia.org/wiki/Simulated_annealing}{Симуляция отжига}.

    \subsection{Задание функции ошибки}
    Функцию ошибки необходимо задать таким образом, чтобы она отражала качество полученной комбинации мазков,
    причём в любой точке направление её уменьшения соответствовало направлению улучшения результата.
    Помимо напрашивающегося \href{https://en.wikipedia.org/wiki/Mean_squared_error}{MSE}

    \begin{equation}\label{eq:equation}
        MSE = \sum_{y = 0}^{y < height} { \sum_{x = 0}^{x < width} { \sum_{c \in  \left\{ r, g, b \right\} } { \left( {\overrightarrow {rendered_{x, y}}}_c - {\overrightarrow{original_{x, y}}}_c\right)^2 }}}
    \end{equation}

    , повсеместно используемого при работе с изображениями, функция ошибки «наказывает» наложение мазков, а также

    \subsection{Растеризация мазков}\label{subsec:rasterization}

    // TODO: написать про разные формы, адаптации под видеокарту и т.д.

    \section{Технические аспекты}\label{sec:tecnical}

    \subsection{Основное}\label{subsec:major}
    Программа написана на языке программирования C++(так как требовалась максимальная скорость), сборка осуществляется с помощью CMake.
    Проект можно скомпилировать под Windows (компилятор MSVC) и под Linux (тестировалось на g++-10).

    Код хранится в \href{https://github.com/donRumata03/Painter}{guthub-репозитории (кликабельно)}.

    \subsection{Библиотеки}\label{subsec:libs}

    \subsubsection{OpenCV}
    Для работы с изображениями используется OpenCV, но не модуль машинного обучения, а лишь примитивные операции с изображениями:
    прочтение из популярных форматов, сохранение в них, хранение и копирование матрицы пикселей и т.д.

    \subsubsection{Pythonic}
    Для работы проекта также необходима библиотека «\href{https://github.com/donRumata03/pythonic}{pythonic}»: она написана мной, подключается также через CMake.
    Она отвечает за базовые функции и структуры данных.
    Я использую её во всех более или менее крупных проектах на C++.
    В ней на данный момент есть:
    \begin{itemize}
        \item Простые вспомогательные функции для работы со строками, контейнерами, форматированного вывода
        \item Вызов питоновской библиотеки matplotlib для построения графиков
        \item Базовые алгоритмы наподобие бинарного поиска и дерева отрезков
        \item Функционал для работы со временем, в том числе — анализатор последовательных запусков процесса
        \item Платформонезависимая работа с кодировками и файловыми системами
        \item Примитивы для вычислительной геометрии
        \item Функции для работы со статистикой
        \item Многомерный шаблонный массив с количеством измерений, изменяемом в run-time
        \item Сглаживание функций и построение примерной функции распределения в пространстве с заданной размерностью по набору sampl-ов с помощью гауссовых ворот
        \item Функционал для работы с многопоточностью, в том числе — thread pool, умеющий снимать нагрузку с ожидающих потоков с помощью std::condition_variable.
    \end{itemize}

    \subsubsection{lunasvg}
    Для работы с SVG используется библиотека \href{https://github.com/sammycage/lunasvg}{lunasvg}.
    P. S. У этой библиотеки отличный автор, он изучает проекты, в которых библиотека используется, и пишет рекомендации о best prictice её использования.

    \subsubsection{PowerfulGA}
    Функционал по методам оптимизации реализован мной и вынесен в отдельную репозиторию: \href{https://github.com/donRumata03/PowerfulGA}{click}
    (там не только Генетический алгоритм, как можно было подумать из названия, но и симуляция отжига, градиентный спуск, метод Ньютона;
    многие другие алгоритмы планируются быть добавленными)
    Более подробное описание в секции → \ref{sec:opimization_algorithms}

    \section {Алгоритмы оптимизации}\label{sec:opimization_algorithms}
    \input{optimization_algorithms}

    \section{Наблюдения}\label{sec:observations}

    \subsection{Неравенство зон}\label{subsec:inequality}
    Когда я заметил, что зоны, на которые Adobe Illustrator делит изображение, могут очень сильно отличаться в размере (отношение площадей может достигать 1000 раз),
    мне захотелось измерить это неравенство численно, чтобы при разработке нового алгоритма измерять его качество в том числе по этому параметру.

    Существует большое количество метрик, я решил выбрать основные из них:
    \begin{itemize}
        \item Индекс Джини (вместе с кумулятивным графиком распределения дохода (также известен как \href{https://en.wikipedia.org/wiki/Lorenz_curve}{кривая Лоренца}))
        \item Процент «дохода» 1\% самых богатых от общего «дохода» (В случае зон вместо дохода используется занимаемая площадь).
        \item Процент самых богатых, имеющих в сумме 50\% от общего дохода.
    \end{itemize}

    Индекс Джини рассчитывается как отношение площади между кривой Лоренца и «линией равенства» к площади под линией равенства.
    Иными словами, $G = \frac{A}{A + B}$ на этой схеме:

    \begin{figure}[h!]\label{fig:lorenz_curve}
        \centering
        \includegraphics[width=0.75\textwidth]{../images/typical_lorenz_curve.png}
        \caption{Типичная кривая Лоренца}
    \end{figure}
    Альтернативный способ посчитать коэффициент, использующийся в реализации:
    \begin{equation}
        G = \frac{\sum_{i=1}^{n}  \sum_{j=i+1}^{n}  \left| y_i - y_j \right|}{n \cdot \sum_{i=1}^{n} y_i}
    \end{equation}
    Чем индекс выше, тем большее неравенство наблюдается в стране.
    Более того, использование именно этой метрики позволяет комплексно оценить неравенство между анализируемыми объектами —
    в отличие от рассмотрения процентов дохода заданного квантиля.


    Результаты оказались впечатляющими:
    \begin{itemize}
        \item $Gini\_index \approx 76\%$
        \item 1\% крупнейших зон покрывают ≈ 18\% изображения
        \item 6.25\% зон покрывают половину изображения
    \end{itemize}

    Так выглядит кумулятивный график распределения площади:
    \begin{figure}[h!]\label{fig:cumulative_inequality_graph}
        \centering
        \includegraphics[width=0.75\textwidth]{../images/cumulative_inequality_graph.jpg}
        \caption{Кривая лоренца для зон}
    \end{figure}

    Нетрудно заметить, что ни в одной стране мира нет такого неравенства, как среди зон:

    \begin{figure}[h!]\label{fig:gini_index_world}
        \centering
        \includegraphics[width=0.75\textwidth]{../images/gini_index_world.jpg}
        \caption{Индекс Джини по странам мира}
    \end{figure}
    Даже в ЮАР индекс Джини составляет 57.8\%.


    \section{Дальнейшее развитие}\label{sec:todo}
    Несмотря на то, что программа уже работоспособна, есть ещё много идей и планов по её усовершенствованию:
    \begin{itemize}
        \item Внедрить \textit{быстрый пересчёт функции ошибки} — это улучшение давно напрашивается,
                но оно несколько теряет в эффективности из-за того, что в одной мутации в среднем изменяется
                не так мало мазков (однако это количество убывает со временем).
                В настоящий момент ведётся работа над внедрением.
        \item Разделение мазков по слоям.
                Нетрудно заметить, что при рисовании картин художники сначала проходятся по холсту черновыми мазками большого размера, а затем — прорабатывают детали.
                Таких уровней детализации зачастую бывает немало.

        Пример того, как художник (\href{https://www.youtube.com/watch?v=VaXHtai2alU}{https://www.youtube.com/watch?v=VaXHtai2alU}) рисует картину по слоям:


        \begin{figure}[h!]
            \centering
            \subfloat{\includegraphics[width=0.24\textwidth]{../images/painting_example_layer_0.png}}
            \subfloat{\includegraphics[width=0.24\textwidth]{../images/painting_example_layer_1.png}}
            \subfloat{\includegraphics[width=0.24\textwidth]{../images/painting_example_layer_2.png}}
            \subfloat{\includegraphics[width=0.24\textwidth]{../images/painting_example_layer_3.png}}
            \caption{ Фон | Рельеф фона | Детализация заднего плана | Основные объекты}
            \label{fig:layered_painting}
        \end{figure}


                Поэтому стоит попробовать сначала заполнять картинку толстыми, грубыми мазками
                (то есть просто с большей шириной, а в реальной жизни это будет отражаться в большем размере кисти и в более сильном нажатии).
        \item Добавить использование локальных методов оптимизации.
                Такие методы, как \textbf\textit{{градиентный спуск}} и \textbf\textit{{метод Ньютона}} позволяют достичь гораздо большей скорости сходимости
                (в случае метода ньютона — сходимость \href{http://w.ict.nsc.ru/books/textbooks/akhmerov/mo_unicode/4.html}{квадратичная}),
                но требуют умения посчитать градиент функции ошибки в любой точке, а также вектор вторых производных по каждому из аргументов.

                Сами алгоритмы реализованы и находятся в \href{https://github.com/donRumata03/PowerfulGA/blob/master/other_optimization/local_optimization.cpp}{этой папке}.
                Предусмотрена опция подсчёта первой и вторых производных через подстановку близких значений параметров:

                \begin{equation}
                    f'(x_0) \approx \frac{f(x_0 + \Delta x) - f(x_0)}{\Delta x}
                \end{equation}

                Однако в случае с мазками при маленьких изменениях параметров функция ошибки остаётся неизменной, так как это приводит к такому же набору закрашенных пикселей.
                Соответственно, нужно либо радикально увеличивать разрешение изображения, либо использовать аналитические методы.
                То есть нужно математически посчитать изменение функции ошибки при бесконечно малом изменении из параметров функции.

        \item \label{item:testing_system} Организовать систему тестирования различных алгоритмов на различных функциях.
        Звучит как нечто весьма простое, но реальность сложнее, чем кажется.
        Напрашивающийся вариант — дать каждому алгоритму заданное количество вычислений функции ошибки и сравнить, какой результат они получат.

        Однако функция ошибки нелинейная, поэтому сложно будет понять,
        насколько сильному различию в качестве алгоритма соответствует полученная численная разница в результатах.

        Целесообразно сравнивать количество итераций, требующееся алгоритмам для получения заданного результата.
        Но и тут не всё так просто: нельзя просто запустить алгоритмы на неограниченное количество итераций
        и ждать дотижения нужного значения функции,
        так как во многих из них (как минимум — в моей модификации ГА) то,
        как будет проведена каждая отдельная итерация, сильно зависит от процента выполнения на момент её прохождения:
        происходит планирование,  использующее информацию о максимальном количестве итераций.


        Поэтому нет никакого другого выхода, кроме того, чтобы запускать этот алгоритм с рахым количеством итераций и смотреть, когда он в среднем будет доходить до заданного порога.
        Это необходимо автоматизировать.
        В идеальном случае для поиска порога можно было бы использовать бинарный поиск, но в реальности (с поправкой на шум) имеет смысл использовать эвристическую модификацию н-арного поиска (объяснить!).
        Для полной оценки планируется построить график достаточного количества итераций от nребуемого значения функции в интересующей нас зоне.

        \item Улучшить алгоритм поиска цветов и разделения на зоны.

                Сейчас для разделения изображения на зоны используется Adobe Illustrator.
                По заданному количеству цветов (и, следовательно, уровню детализации) он разделяет изображение на зоны,
                присваивая каждой какой-то из цветов палитры так, чтобы он хорошо .
                Сама палитра тоже формируется в ходе работы алгоритма.

                Скорее всего, для этого используется один из популярных алгоритмов, описанных \href{https://en.wikipedia.org/wiki/Color_quantization}{здесь}, или некая проприетарная их вариация.
                Зоны, на которые происходит деление, описываются частями плоскости, ограниченными кривыми безье — «path»  формате $svg$.
                Несмотря на то что формально алгоритм выполняет свою работу, большое количество зон имеет очень продолговатую форму,
                а также наблюдается неимоверный разброс в размерах между разными зонами (см. \ref{subsec:inequality}):
                всё это уменьшает эффективность процесса.


        \item Перенести графические вычисления на видеокарту.
                Также напрашивающееся улучшение.
                Это может существенно ускорить работу алгоритма, но только генетического (так как при отжиге нельзя распараллелить вычисление для целой популяции),
                причём только в случае, если не используется быстрый пересчёт функции ошибки или мутирует очень много мазков одновременно.
                Как бы то ни было, когда-нибудь стоит добавить эту возможность.
                Тестовый проект с использованием OpenCV я уже написал.
                Адаптацию алгоритма под видеокарту можно посмотреть здесь: \ref{}.



    \end{itemize}

\end{document}