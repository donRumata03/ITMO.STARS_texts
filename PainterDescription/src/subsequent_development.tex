Несмотря на то, что программа уже работоспособна, есть ещё много идей и планов по её усовершенствованию:


 \subsection{Внедрить \textit{быстрый пересчёт функции ошибки}}
Это улучшение давно напрашивается,
но оно несколько теряет в эффективности из-за того, что в одной мутации в среднем изменяется
не так мало мазков (однако это количество убывает со временем).
В настоящий момент ведётся работа над внедрением.

\subsection{Разделение мазков по слоям}
 Нетрудно заметить, что при рисовании картин художники сначала проходятся по холсту черновыми мазками большого размера, а затем — прорабатывают детали.
 Таких уровней детализации зачастую бывает немало.

 Пример того, как художник (\href{https://www.youtube.com/watch?v=VaXHtai2alU}{https://www.youtube.com/watch?v=VaXHtai2alU}) рисует картину по слоям:

\begin{figure}[h!]
    \centering
    \subfloat{\includegraphics[width=0.24\textwidth]{painting_example_layer_0.png}}
    \subfloat{\includegraphics[width=0.24\textwidth]{painting_example_layer_1.png}}
    \subfloat{\includegraphics[width=0.24\textwidth]{painting_example_layer_2.png}}
    \subfloat{\includegraphics[width=0.24\textwidth]{painting_example_layer_3.png}}
    \caption{ Фон | Рельеф фона | Детализация заднего плана | Основные объекты}
    \label{fig:layered_painting}
\end{figure}


Поэтому стоит попробовать сначала заполнять картинку толстыми, грубыми мазками
(то есть просто с большей шириной, а в реальной жизни это будет отражаться в большем размере кисти и в более сильном нажатии).

\subsection{Добавить возможность использования локальных методов оптимизации}
Такие методы, как \textbf\textit{{градиентный спуск}} и \textbf\textit{{метод Ньютона}} позволяют достичь гораздо большей скорости сходимости
(в случае метода ньютона — сходимость \href{http://w.ict.nsc.ru/books/textbooks/akhmerov/mo_unicode/4.html}{квадратичная}),
но требуют умения посчитать градиент функции ошибки в любой точке, а также вектор вторых производных по каждому из аргументов.

Сами алгоритмы реализованы и находятся в \href{https://github.com/donRumata03/PowerfulGA/blob/master/other_optimization/local_optimization.cpp}{этой папке}.
Предусмотрена опция подсчёта первой и вторых производных через подстановку близких значений параметров:

\begin{equation}
    f'(x_0) \approx \frac{f(x_0 + \Delta x) - f(x_0)}{\Delta x}
\end{equation}

Однако в случае с мазками при маленьких изменениях параметров функция ошибки остаётся неизменной, так как это приводит к такому же набору закрашенных пикселей.
Соответственно, нужно либо радикально увеличивать разрешение изображения, либо использовать аналитические методы.
То есть нужно математически посчитать изменение функции ошибки при бесконечно малом изменении из параметров функции.

 \subsection{Организовать систему тестирования различных алгоритмов на различных функциях}\label{itm:testing_system}
Звучит как нечто весьма простое, но реальность сложнее, чем кажется.
Напрашивающийся вариант — дать каждому алгоритму заданное количество вычислений функции ошибки и сравнить, какой результат они получат.

Однако функция ошибки нелинейная, поэтому сложно будет понять,
насколько сильному различию в качестве алгоритма соответствует полученная численная разница в результатах.

Целесообразно сравнивать количество итераций, требующееся алгоритмам для получения заданного результата.
Но и тут не всё так просто: нельзя просто запустить алгоритмы на неограниченное количество итераций
и ждать дотижения нужного значения функции,
так как во многих из них (как минимум — в моей модификации ГА) то,
как будет проведена каждая отдельная итерация, сильно зависит от процента выполнения на момент её прохождения:
происходит планирование,  использующее информацию о максимальном количестве итераций.


Поэтому нет никакого другого выхода, кроме того, чтобы запускать этот алгоритм с рахым количеством итераций и смотреть, когда он в среднем будет доходить до заданного порога.
Это необходимо автоматизировать.
В идеальном случае для поиска порога можно было бы использовать бинарный поиск, но в реальности (с поправкой на шум) имеет смысл использовать эвристическую модификацию н-арного поиска (объяснить!).
Для полной оценки планируется построить график достаточного количества итераций от nребуемого значения функции в интересующей нас зоне.

\subsection{Улучшить алгоритм поиска цветов и разделения на зоны}

Сейчас для разделения изображения на зоны используется Adobe Illustrator.
По заданному количеству цветов (и, следовательно, уровню детализации) он разделяет изображение на зоны,
присваивая каждой какой-то из цветов палитры так, чтобы он хорошо .
Сама палитра тоже формируется в ходе работы алгоритма.

Скорее всего, для этого используется один из популярных алгоритмов, описанных \href{https://en.wikipedia.org/wiki/Color_quantization}{здесь}, или некая проприетарная их вариация.
Зоны, на которые происходит деление, описываются частями плоскости, ограниченными кривыми безье — «path»  формате $svg$.
Несмотря на то что формально алгоритм выполняет свою работу, большое количество зон имеет очень продолговатую форму,
а также наблюдается неимоверный разброс в размерах между разными зонами (см. \ref{subsec:inequality}):
всё это уменьшает эффективность процесса.

// TODO: написать про свой алгоритм и склеивание зон

\subsection{Перенести графические вычисления на видеокарту}\label{subsec:move_graphics_to_videocard}
Также напрашивающееся улучшение.
Это может существенно ускорить работу алгоритма, особенно — генетического (так как при нём можно распараллелить вычисление для целой популяции),
причём только в случае, если не используется быстрый пересчёт функции ошибки или мутирует очень много мазков одновременно.
Как бы то ни было, когда-нибудь стоит добавить эту возможность.
Тестовый проект с использованием OpenCL я уже написал.

Изначальная картинка будет переноситься в видеопамять один раз — в начале работы программы.
Выделить память для матрицы можно также один раз, а потом каждый раз её очищать (эту операцию можно производить параллельно).

Если использовать видеокарту для распараллеливания вычислений, встаёт вопрос, на каком именно уровне производить разделение.
Варианты такие:
\begin{enumerate}
    \item Каждое изображение — на своём потоке.
    Такой способ подходит только для ГА в случае огромного размера поколения (так как потоков у видеокарты порядка нескольких тысяч).
    Для отжига — никогда.

    \item Каждый мазок — на своём потоке.
                Тут возникают проблемы с синхронизацией, так как порядок наложения важен: как минимум не должны появляться в хаотическом порядке пиксели из мазков разного цвета.
                Даже если происходит смешение цветов при наложении, синхронизация важна.
                Это можно сделать через дополнительную струкрутру данных в виде прямоугольной матрицы, в которой для каждого пикселя будет записываться список цветов с приоритетами
                (индексами мазков, а значит, и числами, определяющими порядок слоёв).
                Потом уже независимо для каждого пикселя будет происходить обработка смешения или наложения с замещением «попавших» на него цветов.
                Всё упирается в умение синхронизировать потоки.
                Тут нужно либо симуляцию мьютекса для каждого пикселя (то есть матрицу булевых значений «занят-не занят»),
                либо умение распределить мазки по потокам так, чтобы в каждый момент времени не было никаких двух с накладывающимися bounding-box'ами.

                В первом случае либо нужно покупать видеокарту с поддержкой атомарных значений, либо придётся вставлять дополнительные проверки,
                чтобы два потока не прочитали почти одновременно состояние «не занят»  и не зашли туда до того, как какой-либо из них успеет записать состояние «закрыто».

                Во втором случае уменьшится количество потоков, одновременно работающих над одной «картиной».


    \item Проводить распараллеливыание на графическом примитиве нисшего уровня, использующемся в данном алгоритме (см. \ref{subsec:rasterization}).
                Например, полигоны или круги.
                Видеокарта умеет эффективно отрисовывать такие примитивы.
                Однако количество точек в примитивах обычно невелико: существенно меньше, чем ядер в видеокарте.
\end{enumerate}
Причём всегда можно комбинировать разделения на разных уровнях.

Когда будет произведена растеризация, на той же видеокарте посчитается функция ошибки: в этом случае легко сделать это независимо для каждого пикселя.
Единственное — нужно помнить, что для добавления наказания за наложения и пустоты в функцию ошибки надо составлять дополнительные матрицы, в которых это будет указано.


Адаптация алгоритмов под видеокарту описана здесь: \ref{subsec:rasterization}.